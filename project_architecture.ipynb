{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f4248ad",
   "metadata": {},
   "source": [
    "# Project architecture (only function comments no code!)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e98fc0",
   "metadata": {},
   "source": [
    "## Task:\n",
    "* ## Initial Ideas, First Tests "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278d4b38",
   "metadata": {},
   "source": [
    "### Things to be implemented independendly of anomly detetor used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce8fb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genereate peporcessed images \n",
    "\n",
    "\"\"\"generates training images by applying preprocessing, e.g \n",
    "    - aggregation\n",
    "    - image brightness normalization\n",
    "    - speeration of color channel\n",
    "     - maybe grayscale\n",
    "     \n",
    "     Make options such as grayscale optional etc!!!\n",
    "\n",
    "    input: our data folder!\n",
    "    \n",
    "    output: a list of image files stored in a folder (do this so it is cleanly sperated from our dataloader)\n",
    "    \n",
    "\"\"\"\n",
    "#TODO apply already written image integration to all images and add further stuff!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2e6e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def look_up labels\n",
    "\"\"\"\n",
    "    returns the area (rectangle) in which an anomly is detected\n",
    "    \n",
    "    only used for validation set (we don not have labels anywhere else)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c1fb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate\n",
    "\"\"\"\n",
    "    Input:\n",
    "        image+reconstruced one\n",
    "        \n",
    "    needs to get:\n",
    "        - area where anomly was detected (using calculate differences)\n",
    "        - areas from labels\n",
    "        \n",
    "    Output evaluation metric (Intersection over Union see slides!)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae62a48",
   "metadata": {},
   "source": [
    "### Things to implement if we want to use autoencoders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a59f6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate differences in input to recunstruced output:\n",
    "\"\"\"\n",
    "Input: two images the original one and the reconstructed one (reconstructed one has small differences)\n",
    "\n",
    "Output: rectangles marking areas of difference\n",
    "\n",
    "Methodes: Do research on best methodes how to do this first!\n",
    "My (not well researched) idea: try out pixel wise KL-divergence, or someone also mentioned Wassersteindistance\n",
    "try different methodes\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391b0b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataloader + autoencoder \n",
    "\n",
    "\"\"\"\n",
    "Input: folder of preprocessed images\n",
    "\n",
    "Output: preprocessed image +reconstructed one (input to evaluate)\n",
    "\n",
    "\n",
    "Idea for Methode:\n",
    "overfitting is our biggest enemy! We need to try to keep model complexity low!\n",
    "Hence, don't take whole image as input, take croped out part as input!\n",
    "Hence dataloader should generate criopped out images!\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI_2",
   "language": "python",
   "name": "ai_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
