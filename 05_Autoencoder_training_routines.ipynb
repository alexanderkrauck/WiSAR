{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import importlib\n",
    "from IPython.display import clear_output\n",
    "import json\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "import utils.architectures as architectures\n",
    "from utils.basic_function import draw_labels\n",
    "import utils.data as data\n",
    "import utils.sub_architectures as sub_architectures\n",
    "\n",
    "#__import__('3_project.evaluate')\n",
    "#os.chdir('3_project')\n",
    "\n",
    "import utils.evaluation_metrics as evaluation_metrics\n",
    "\n",
    "#evaluate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    return torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### TRAINING UTILS / PLOTTING FUNCTIONS\n",
    "\n",
    "### Trains a (sub-architecture) autoencoder given Model type\n",
    "def train_subarchitecture(\n",
    "    model, \n",
    "    optim, \n",
    "    lr, \n",
    "    num_epochs, \n",
    "    train_loader, \n",
    "    val_loader, \n",
    "    val_data,\n",
    "    device,\n",
    "    saved_model_filename,\n",
    "    plot_training=False, \n",
    "    save_model=True,\n",
    "):\n",
    "\n",
    "    device = get_device()\n",
    "    model = model.to(device=device)\n",
    "\n",
    "    criterion = nn.MSELoss() #Loss function\n",
    "    optimizer = optim(model.parameters(), lr=lr) #Optimizer\n",
    "\n",
    "    lr_schedule = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer,\n",
    "        mode=\"min\", \n",
    "        factor=0.1, \n",
    "        patience=2, \n",
    "        cooldown=1, \n",
    "        verbose=True)\n",
    "\n",
    "    # Training\n",
    "    train_loss = []\n",
    "    model.train()\n",
    "    \n",
    "    print(\"Training Progress: \")\n",
    "    time.sleep(0.5)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_losses = []\n",
    "        for x in tqdm(train_loader):\n",
    "\n",
    "            x = x.to(device)\n",
    "            outputs = model(x)\n",
    "\n",
    "            loss = criterion(outputs, x)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_losses.append(loss.detach().cpu().numpy())\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        train_loss.extend(epoch_losses)\n",
    "        lr_schedule.step(np.mean(epoch_losses))\n",
    "        \n",
    "        if(plot_training):\n",
    "            plt.plot(range(len(train_loss)), train_loss)\n",
    "            plt.show()\n",
    "            print(f\"\\rLoss After {epoch+1} Epochs: \"+str(np.mean(epoch_losses)))\n",
    "            if np.mean(epoch_losses) < 0.01:\n",
    "                break\n",
    "\n",
    "        if(save_model):\n",
    "            model.save(filename=saved_model_filename)\n",
    "\n",
    "    return model\n",
    "\n",
    "### Plots \"n\" reconstructed images side-by-side with the original images\n",
    "def show_n_reconstructed_images(model, output_images, n:int):\n",
    "\n",
    "    numpy_images, numpy_output = output_images\n",
    "\n",
    "    print(\"\\nRendering Results...\")\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=n, ncols=3, figsize=(10,5*n))\n",
    "    for idx in range(n):\n",
    "        axes[idx, 0].imshow(numpy_images[idx])\n",
    "        axes[idx, 0].set_title(\"Original Image\")\n",
    "        axes[idx, 1].set_title(\"Reconstructed Image\")\n",
    "        axes[idx, 1].imshow(numpy_output[idx])\n",
    "        axes[idx, 1].set_title(\"Reconstructed Image\")\n",
    "        axes[idx, 2].imshow(abs(numpy_images[idx]-numpy_output[idx]))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "### Plots \"n\" Bounding Box predictions overlaying the target image\n",
    "def show_n_bounding_box_results(approach, dataset, n:int):\n",
    "\n",
    "    for i in range(n):\n",
    "        print(f\"Sample Nr. {i}:\")\n",
    "        sample = dataset[i]\n",
    "        samples = [sample]\n",
    "\n",
    "        res = approach.infer(samples, verbose=0, threshold=0.1)\n",
    "        print(res)\n",
    "\n",
    "        mid_img = sample.get_warped_photo(3,8)\n",
    "        draw_labels(mid_img, [res[0], sample.labels])\n",
    "\n",
    "### Returns a dataset depending on Architecture / Sub-Architecture training\n",
    "def get_dataset(sub):\n",
    "    if(sub):\n",
    "        return data.RandomSamplingGridCutoutDataset(preprocess_image_options = {\n",
    "            \"use_mask\": True,\n",
    "            \"equalize_hist\": False,\n",
    "            \"crop_black\": True,\n",
    "            \"match_histogram\": False\n",
    "        }, crop_shape=(128,128), resample_image_every_n_draws=50)\n",
    "    else:\n",
    "        return data.MultiViewTemporalDataset(mode = \"validation\", preprocess_image_options = {\n",
    "            \"use_mask\": True,\n",
    "            \"equalize_hist\": False,\n",
    "            \"crop_black\": False,\n",
    "            \"match_histogram\": False\n",
    "        }, data_path=\"data\")\n",
    "\n",
    "### Evaluates the model for the Sub-Architecture case exclusively\n",
    "def evaluate_model(model, train_loader, val_loader, device):\n",
    "    images = next(iter(val_loader))\n",
    "    numpy_images = images.numpy()\n",
    "\n",
    "    #Sample outputs\n",
    "    model.eval()\n",
    "    numpy_output = model(images.to(device)).detach().cpu().numpy()\n",
    "\n",
    "    numpy_images = np.transpose(numpy_images, (0, 2, 3, 1))\n",
    "    numpy_output = np.transpose(numpy_output, (0, 2, 3, 1))\n",
    "\n",
    "    return numpy_images, numpy_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss After 1 Epochs: 0.009239045\n",
      "\n",
      "Model Type:  <class 'utils.sub_architectures.ConvolutionalAutoencoderV2'>  Optimizer:  <class 'torch.optim.radam.RAdam'>  Learning rate:  0.01  Epochs:  30\n",
      "Device: NVIDIA GeForce GTX 1060 6GB\n",
      "Inferring on validation dataset, this may take some time...\n",
      "[<class 'utils.sub_architectures.ConvolutionalAutoencoderV2'>, <class 'torch.optim.adagrad.Adagrad'>, 0.01, 30, 0.09758198601077858]\n",
      "[<class 'utils.sub_architectures.ConvolutionalAutoencoderV2'>, <class 'torch.optim.adam.Adam'>, 0.01, 30, 0.022386831275720165]\n",
      "[<class 'utils.sub_architectures.ConvolutionalAutoencoderV2'>, <class 'torch.optim.radam.RAdam'>, 0.01, 30, 0.18177083333333333]\n"
     ]
    }
   ],
   "source": [
    "##### RUN TRAINING ROUTINES #####\n",
    "\n",
    "def train(pretrained_sub_arch: sub_architectures.AbstractTorchArchitecture, show_results=True, load_from_saved=False, save_inference_to_json=False, scoring=False,\n",
    "model=sub_architectures.ConvolutionalAutoencoderV2, optim=torch.optim.Adam, lr=1e-3, num_epochs=25):\n",
    "    \"\"\"\n",
    "    :param AbstractTorchArchitecture pretrained_sub_arch: Pretrained sub-architecture, None if training a sub-architecture\n",
    "    :param show_results bool: If True results will be displayed\n",
    "    :param load_from_saved bool: If True loads pre-trained autoencoder from the \"state_dict\" specified below, otherwise uses uses the pretrained sub-architecture\n",
    "    :param save_inference_to_json bool: If True performs inference on whole dataset and saves bounding box predictions to JSON file\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Get PyTorch \"device\"\n",
    "    device=get_device()\n",
    "    if(torch.cuda.is_available()):\n",
    "        print(\"Device:\", torch.cuda.get_device_name(0))\n",
    "    else:\n",
    "        print(\"Using CPU: consider using GPU for increased performance\")\n",
    "\n",
    "    # Prepare dataset\n",
    "    #sub = True #Set \"sub\" to True to get val_data for Sub-Architectures, False for Architectures\n",
    "    if(pretrained_sub_arch is None):\n",
    "        dataset = get_dataset(sub=True)\n",
    "    else:\n",
    "        dataset = get_dataset(sub=False)\n",
    "\n",
    "    # Dataloader(s)\n",
    "    train_loader = val_loader = torch.utils.data.DataLoader(dataset, batch_size=32, num_workers=0, shuffle=True)\n",
    "\n",
    "    if(pretrained_sub_arch is None):\n",
    "\n",
    "        ### SUB-ARCHITECTURE TRAINING ROUTINE / MODEL ANALYTICS ###\n",
    "\n",
    "        trained_model = train_subarchitecture(                    # HYPERPARAMETERS: \n",
    "            model=model,                                        # Untrained model\n",
    "            optim=optim,                                          # Optimizer\n",
    "            lr=lr,                                                # Learning rate\n",
    "            num_epochs=num_epochs,                                # Epochs\n",
    "                                                                \n",
    "                                                                  # DATALOADERS / OPTIONS:\n",
    "            train_loader=train_loader,                            # Training Dataloader\n",
    "            val_loader=val_loader,                                # Validation Dataloader\n",
    "            val_data=dataset,                                     # Dataset(?)\n",
    "            device=device,                                        # PyTorch \"device\"\n",
    "            saved_model_filename=\"no_histogram_128_trained\",      # Model Filename\n",
    "            plot_training=True,                                   # Plot loss during training\n",
    "            save_model=True                                       # Save model after training\n",
    "        )    \n",
    "\n",
    "        if(show_results):\n",
    "            output_images = evaluate_model(trained_model, trained_model, val_loader, device) #Evaluate model (Get image results)\n",
    "            show_n_reconstructed_images(trained_model, output_images, n=3)\n",
    "\n",
    "        return trained_model\n",
    "\n",
    "    else:\n",
    "        ### MAIN ARCHITECTURE TRAINING ROUTINE ###\n",
    "\n",
    "        autoencoder = sub_architectures.ConvolutionalAutoencoderV2()\n",
    "        #load_from_saved = False #True: Imports model from below filename, False: Uses \"pretrained_sub_arch\" argument as model\n",
    "\n",
    "        if(load_from_saved):\n",
    "            state_dict = torch.load(\"saved_models/ConvolutionalAutoencoderV2/no_histogram_128_trained\", map_location=device)\n",
    "            autoencoder.load_state_dict(state_dict)\n",
    "        else:\n",
    "            autoencoder = pretrained_sub_arch\n",
    "\n",
    "        #TODO: This might need some formatting..\n",
    "\n",
    "        importlib.reload(architectures)\n",
    "        approach = architectures.BasicAutoencoderAnomalyDetectionV1(autoencoder, device=device, image_sizes=(1024,1024)) #Load in autoencoder\n",
    "        approach_score = architectures.ScoreEnsembleAnomalyDetection([approach], [1])\n",
    "\n",
    "        if(show_results):\n",
    "            print(show_results)\n",
    "            print(\"Showing results\")\n",
    "            show_n_bounding_box_results(approach_score, dataset, 5)\n",
    "        \n",
    "        if(save_inference_to_json):\n",
    "            print(\"Inferring on validation dataset, this may take some time...\")                                                       \n",
    "            res = approach_score.infer(dataset, threshold=0.1)\n",
    "            box_list = [el.tolist() for el in res]\n",
    "            box_dict = {}\n",
    "            \n",
    "            for sample, boxes in zip(dataset, box_list):\n",
    "                sample_name = os.path.split(sample.sample_path)[-1]\n",
    "                box_dict[sample_name] = boxes\n",
    "            \n",
    "            with open(\"validation.json\", \"w\") as fi:\n",
    "                json.dump(box_dict, fi)\n",
    "\n",
    "        if(scoring):\n",
    "            with open(\"validation.json\") as fi:\n",
    "                preds = json.load(fi)\n",
    "            with open(\"data/validation/labels.json\") as fi:\n",
    "                targets = json.load(fi)\n",
    "\n",
    "            ap = evaluation_metrics.evaluate(preds, targets)\n",
    "            return ap\n",
    "\n",
    "            print(\"Average Precision: \", ap)       \n",
    "\n",
    "def HyperparameterSearch():\n",
    "\n",
    "    model_types = [sub_architectures.ConvolutionalAutoencoderV2] #NOTE: Only one Model class seems to have the correct \"output size\" currently\n",
    "    optimizers = [torch.optim.Adagrad, torch.optim.Adam, torch.optim.RAdam]\n",
    "    learning_rates = [1e-2, 1e-3, 1e-4, 1e-5]\n",
    "    epoch_values = [10, 20, 30, 40, 50] #NOTE: All optimizers seem to achieve <0.01 loss quickly so don't go past 1 epoch often, breaking training early...\n",
    "    scores = []\n",
    "\n",
    "    models = []\n",
    "\n",
    "    for model_type in model_types:\n",
    "        for optim in optimizers:\n",
    "            for lr in learning_rates:\n",
    "                for epochs in epoch_values:\n",
    "                    trained_model_sub = train(pretrained_sub_arch=None, show_results=False, model=model_type(), optim=optim, lr=lr, num_epochs=epochs)\n",
    "                    print(\"\\nModel Type: \", model_type, \" Optimizer: \", optim, \" Learning rate: \", lr, \" Epochs: \", epochs)\n",
    "                    score = train(pretrained_sub_arch=trained_model_sub, show_results=False, save_inference_to_json=True, load_from_saved=False, scoring=True)\n",
    "                    scores.append([model_type, optim, lr, epochs, score])\n",
    "    \n",
    "    for score in scores:\n",
    "        print(score)\n",
    "\n",
    "HyperparameterSearch()\n",
    "\n",
    "#trained_model_sub = train(pretrained_sub_arch=None, show_results=True) \n",
    "#pretrained_sub_arch=None if training a sub-architecture, otherwise exchange \"None\" placeholder with a pre-trained model\n",
    "\n",
    "#trained_model = train(pretrained_sub_arch=trained_model_sub, show_results=False, save_inference_to_json=False, load_from_saved=True, scoring=True)  \n",
    "#NOTE: When training an Architecture for results, set save_inference_to_json=True to infer the validation dataset (costly)\n",
    "#As an alternative, show_results=True to see results from a subset of the dataset\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8be9447539d9575c41e4c0fdb9e82ec5973f32843cf2f527d93a54d8d36b47fb"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
